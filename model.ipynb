{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from env import host, user, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0           0             0         0       3    male  22.0      1      0   \n",
       "1           1             1         1       1  female  38.0      1      0   \n",
       "2           2             2         1       3  female  26.0      0      0   \n",
       "3           3             3         1       1  female  35.0      1      0   \n",
       "4           4             4         0       3    male  35.0      0      0   \n",
       "\n",
       "      fare embarked  class deck  embark_town  alone  \n",
       "0   7.2500        S  Third  NaN  Southampton      0  \n",
       "1  71.2833        C  First    C    Cherbourg      0  \n",
       "2   7.9250        S  Third  NaN  Southampton      1  \n",
       "3  53.1000        S  First    C  Southampton      0  \n",
       "4   8.0500        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    891 non-null    int64  \n",
      " 1   passenger_id  891 non-null    int64  \n",
      " 2   survived      891 non-null    int64  \n",
      " 3   pclass        891 non-null    int64  \n",
      " 4   sex           891 non-null    object \n",
      " 5   age           714 non-null    float64\n",
      " 6   sibsp         891 non-null    int64  \n",
      " 7   parch         891 non-null    int64  \n",
      " 8   fare          891 non-null    float64\n",
      " 9   embarked      889 non-null    object \n",
      " 10  class         891 non-null    object \n",
      " 11  deck          203 non-null    object \n",
      " 12  embark_town   889 non-null    object \n",
      " 13  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preapare the data: Drop columns \n",
    "columns_to_drop = ['Unnamed: 0','pclass', 'embark_town', 'embarked', 'deck',  'parch', 'passenger_id', 'age']\n",
    "titanic.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex  sibsp     fare  class  alone\n",
       "0         0    male      1   7.2500  Third      0\n",
       "1         1  female      1  71.2833  First      0\n",
       "2         1  female      0   7.9250  Third      1\n",
       "3         1  female      1  53.1000  First      0\n",
       "4         0    male      0   8.0500  Third      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode survived ==> This is the target variable and targets do not need to be encoded for classification decision trees\n",
    "titanic.rename(columns={'survived':\"survival\"}, inplace=True)\n",
    "titanic['survived'] = titanic.survival.apply(lambda n: 'survived' if n > 0 else 'died')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Class and Sex as these are features we want to explore. The additional features of fare, alone, sibsp are already encoded. \n",
    "dummies = pd.get_dummies(titanic[['class', 'sex']], drop_first=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat dummies df with Titanic \n",
    "titanic = pd.concat([titanic, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop additional columns after encoding\n",
    "titanic.drop(columns={'sex','class','survival'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, validate, and test\n",
    "#stratidfy by survived \n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target == survived\n",
    "#features == sex, class, fare, alone, siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "died        307\n",
       "survived    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determine the baseline prediction by finding the mode for survived\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish baseline prediction\n",
    "train['baseline_prediction'] = 'died'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate baseline accuracy\n",
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up Model 1 Decision Tree with a max depth of 2\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the decision tree to training data\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check labels for class names\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize decision tree: \n",
    "\n",
    "#import graphviz\n",
    "#from graphviz import Graph\n",
    "#\n",
    "#dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=clf.classes_)\n",
    "#graph = graphviz.Source(dot_data) \n",
    "#\n",
    "#graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'died', 'died', 'survived', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the first 5 predictions from model 1\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sibsp      fare  alone  survived  class_Second  class_Third  sex_male  \\\n",
       "583      0   40.1250      1      died             0            0         1   \n",
       "165      0   20.5250      0  survived             0            1         1   \n",
       "50       4   39.6875      0      died             0            1         1   \n",
       "259      0   26.0000      0  survived             1            0         0   \n",
       "306      0  110.8833      1  survived             0            0         0   \n",
       "\n",
       "    baseline_prediction  \n",
       "583                died  \n",
       "165                died  \n",
       "50                 died  \n",
       "259                died  \n",
       "306                died  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the predictions against the actuals\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.04255319, 0.95744681]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the probabilities for each class\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Model Score: \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265,  42],\n",
       "       [ 58, 133]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evealuate with Cofusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          died  survived\n",
       "died       265        42\n",
       "survived    58       133"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.82      0.86      0.84       307\n",
      "    survived       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate with Classififcation Report\n",
    "model_1_report = classification_report(y_train, y_pred)\n",
    "print(model_1_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has an accuracy score of 79.92%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print(f'Model has an accuracy score of {accuracy_score(y_pred, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate is: 53.21%\n",
      "False Positive Rate is: 11.65%\n",
      "True Negative Rate is: 26.71%\n",
      "False Negative Rate is: 8.43%\n"
     ]
    }
   ],
   "source": [
    "#Rates from confusions matrix \n",
    "#Where dead is being treated as the positive class and survived is the negative class\n",
    "\n",
    "sample_count = len(train)\n",
    "\n",
    "tp = 265\n",
    "fp = 58\n",
    "fn = 42\n",
    "tn = 133\n",
    "\n",
    "print(f'True Positive Rate is: {tp/sample_count:.2%}')\n",
    "print(f'False Positive Rate is: {fp/sample_count:.2%}')\n",
    "print(f'True Negative Rate is: {tn/sample_count:.2%}')\n",
    "print(f'False Negative Rate is: {fn/sample_count:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76      , 0.82043344])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision\n",
    "precision_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69633508, 0.86319218])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "recall_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72677596, 0.84126984])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1-score\n",
    "f1_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([191, 307])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support\n",
    "precision_recall_fscore_support(y_train, y_pred, labels=['survived', 'died'], average=None)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up Model 2 using a decision treet with a max depth of 3 \n",
    "clf_2 = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the training data to Model 2 \n",
    "clf_2 = clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check labels\n",
    "clf_2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the decision tree:\n",
    "\n",
    "#dot_data = export_graphviz(clf_2, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=clf_2.classes_)\n",
    "#graph = graphviz.Source(dot_data) \n",
    "#\n",
    "#graph.render('titanic_2_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'died', 'died', 'survived', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the first 5 predictions from model 2 \n",
    "y_pred_2 = clf_2.predict(X_train)\n",
    "y_pred_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69827586, 0.30172414],\n",
       "       [0.69827586, 0.30172414],\n",
       "       [0.69827586, 0.30172414],\n",
       "       [0.07142857, 0.92857143],\n",
       "       [0.01923077, 0.98076923]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the probabilities for each class\n",
    "y_pred_proba = clf_2.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Model 2 Score: \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[276,  31],\n",
       "       [ 57, 134]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evealuate with Cofusion Matrix\n",
    "confusion_matrix(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>276</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          died  survived\n",
       "died       276        31\n",
       "survived    57       134"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred_2), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_report = classification_report(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.83      0.90      0.86       307\n",
      "    survived       0.81      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_2_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Model 2 performs better on in-sample data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.82      0.86      0.84       307\n",
      "    survived       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        died       0.83      0.90      0.86       307\n",
      "    survived       0.81      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_1_report, model_2_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Model 2 performs better on the out-of-sample data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 1 on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.76\n"
     ]
    }
   ],
   "source": [
    "#Model 1 Accuracy for Validate Data set\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.80      0.83      0.81       132\n",
      "    survived       0.70      0.66      0.68        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.75      0.74      0.74       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 2 on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Model 2 Accuracy for Validate Data set\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf_2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = clf_2.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.80      0.87      0.83       132\n",
      "    survived       0.76      0.65      0.70        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.76      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sibsp      fare  alone  survived  class_Second  class_Third  sex_male\n",
       "583      0   40.1250      1      died             0            0         1\n",
       "165      0   20.5250      0  survived             0            1         1\n",
       "50       4   39.6875      0      died             0            1         1\n",
       "259      0   26.0000      0  survived             1            0         0\n",
       "306      0  110.8833      1  survived             0            0         0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "      <td>true positive</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>23</td>\n",
       "      <td>168</td>\n",
       "      <td>false positive</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict_death predict_survive   predict_death predict_survive\n",
       "actual_death             300               7   true positive  false negative\n",
       "actual_survive            23             168  false positive   true negative"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])\n",
    "rubric_df = pd.DataFrame([['true positive', 'false negative'],['false positive', 'true negative']], columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])\n",
    "joined = pd.concat([conf_df, rubric_df], axis=1)\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.93      0.98      0.95       307\n",
      "    survived       0.96      0.88      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.94      0.93      0.94       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(clf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    #accuracy = clf.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    clf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = clf[0][0] / clf[0].sum()\n",
    "    fpr = clf[0][1] / clf[1].sum()\n",
    "    tnr = clf[1][1] / clf[1].sum()\n",
    "    fnr = clf[1][0] / clf[0].sum()\n",
    "    print(f'''\n",
    "    Confusion Matrix: \\n {clf},\n",
    "    '--------------------------------',\n",
    "    The True Positive Rate is {tpr:.2}, The False Positive Rate is {fpr:.2},\n",
    "    The True Negative Rate is {tnr:.2}, and the False Negative Rate is {fnr:.2}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.98, The False Positive Rate is 0.037,\n",
      "    The True Negative Rate is 0.88, and the False Negative Rate is 0.075\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.928793</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.944396</td>\n",
       "      <td>0.928390</td>\n",
       "      <td>0.935207</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.940762</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939207</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.928793  0.977199  0.952381  307.000000\n",
       "survived       0.960000  0.879581  0.918033  191.000000\n",
       "accuracy       0.939759  0.939759  0.939759    0.939759\n",
       "macro avg      0.944396  0.928390  0.935207  498.000000\n",
       "weighted avg   0.940762  0.939759  0.939207  498.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model1_report = get_metrics_binary(conf_df)\n",
    "rf_model1_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model 2 with increased min_samples_leaf and decreased mx_depth\n",
    "rf_2 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=4, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=123)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the training data to random forest model 2\n",
    "rf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the y_pred\n",
    "y_pred = rf_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Accuracy of random forest classifier on training set: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Return accuracy metric for random forest model 2\n",
    "print('Model 2 Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the confusion matrix for model 2...treat death as the positive class\n",
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.94, The False Positive Rate is 0.099,\n",
      "    The True Negative Rate is 0.68, and the False Negative Rate is 0.2\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.938111</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.675393</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.806752</td>\n",
       "      <td>0.818887</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.841560</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.832356</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.822857  0.938111  0.876712  307.000000\n",
       "survived       0.871622  0.675393  0.761062  191.000000\n",
       "accuracy       0.837349  0.837349  0.837349    0.837349\n",
       "macro avg      0.847239  0.806752  0.818887  498.000000\n",
       "weighted avg   0.841560  0.837349  0.832356  498.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return metrics report for evaluating model 2 \n",
    "rf_model2_report = get_metrics_binary(conf_df)\n",
    "rf_model2_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Random Forest Metrics: \n",
      "\n",
      "               precision    recall  f1-score     support\n",
      "died           0.928793  0.977199  0.952381  307.000000\n",
      "survived       0.960000  0.879581  0.918033  191.000000\n",
      "accuracy       0.939759  0.939759  0.939759    0.939759\n",
      "macro avg      0.944396  0.928390  0.935207  498.000000\n",
      "weighted avg   0.940762  0.939759  0.939207  498.000000\n",
      "--------------------------------------\n",
      "Model 2 Random Forest Metrics: \n",
      "\n",
      "               precision    recall  f1-score     support\n",
      "died           0.822857  0.938111  0.876712  307.000000\n",
      "survived       0.871622  0.675393  0.761062  191.000000\n",
      "accuracy       0.837349  0.837349  0.837349    0.837349\n",
      "macro avg      0.847239  0.806752  0.818887  498.000000\n",
      "weighted avg   0.841560  0.837349  0.832356  498.000000\n"
     ]
    }
   ],
   "source": [
    "print(f'Model 1 Random Forest Metrics: \\n\\n {rf_model1_report:}')\n",
    "print('--------------------------------------')\n",
    "print(f'Model 2 Random Forest Metrics: \\n\\n {rf_model2_report:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model 3 with increased min_samples_leaf and decreased mx_depth\n",
    "rf_3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=10,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=8, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3.fit(X_train, y_train)\n",
    "y_pred = rf_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf_3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.95, The False Positive Rate is 0.084,\n",
      "    The True Negative Rate is 0.63, and the False Negative Rate is 0.23\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.806094</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.871257</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.633508</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.844653</td>\n",
       "      <td>0.790695</td>\n",
       "      <td>0.804531</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.835671</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.820074</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.806094  0.947883  0.871257  307.000000\n",
       "survived       0.883212  0.633508  0.737805  191.000000\n",
       "accuracy       0.827309  0.827309  0.827309    0.827309\n",
       "macro avg      0.844653  0.790695  0.804531  498.000000\n",
       "weighted avg   0.835671  0.827309  0.820074  498.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model3_report = get_metrics_binary(conf_matrix)\n",
    "rf_model3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Random Forest Model 1 performs the best on the training data set***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the models with out of sample data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy of random forest classifier on validate set: 0.78\n",
      "------------\n",
      "Model 2 Accuracy of random forest classifier on validate set: 0.79\n",
      "------------\n",
      "Model 3 Accuracy of random forest classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_validate)\n",
    "print('Model 1 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))\n",
    "\n",
    "print('------------')\n",
    "y_pred = rf_2.predict(X_validate)\n",
    "print('Model 2 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf_2.score(X_validate, y_validate)))\n",
    "\n",
    "print('------------')\n",
    "y_pred = rf_3.predict(X_validate)\n",
    "print('Model 3 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf_3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Random Forest Model 1 performs better on the validate data set***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sibsp         498 non-null    int64  \n",
      " 1   fare          498 non-null    float64\n",
      " 2   alone         498 non-null    int64  \n",
      " 3   survived      498 non-null    object \n",
      " 4   class_Second  498 non-null    uint8  \n",
      " 5   class_Third   498 non-null    uint8  \n",
      " 6   sex_male      498 non-null    uint8  \n",
      "dtypes: float64(1), int64(2), object(1), uint8(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Confirm training data set is good to work with\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data without limiting the dimensions (using all features for this model)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 47 144]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.75, and the False Negative Rate is 0.15\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.849359</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.856220</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.810073</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820530</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.820822</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.849359  0.863192  0.856220  307.000000\n",
       "survived       0.774194  0.753927  0.763926  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.811776  0.808559  0.810073  498.000000\n",
       "weighted avg   0.820530  0.821285  0.820822  498.000000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_binary(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 47 144]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.75, and the False Negative Rate is 0.15\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.849359</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.856220</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.810073</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820530</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.820822</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.849359  0.863192  0.856220  307.000000\n",
       "survived       0.774194  0.753927  0.763926  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.811776  0.808559  0.810073  498.000000\n",
       "weighted avg   0.820530  0.821285  0.820822  498.000000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_report = get_metrics_binary(knn)\n",
    "model_1_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 10 \n",
    "knn_2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data\n",
    "knn_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[266  41]\n",
      " [ 57 134]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.87, The False Positive Rate is 0.21,\n",
      "    The True Negative Rate is 0.7, and the False Negative Rate is 0.19\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.866450</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.794622</td>\n",
       "      <td>0.784010</td>\n",
       "      <td>0.788342</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.801355</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.801410</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.823529  0.866450  0.844444  307.000000\n",
       "survived       0.765714  0.701571  0.732240  191.000000\n",
       "accuracy       0.803213  0.803213  0.803213    0.803213\n",
       "macro avg      0.794622  0.784010  0.788342  498.000000\n",
       "weighted avg   0.801355  0.803213  0.801410  498.000000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 2\n",
    "model_2_report = get_metrics_binary(knn_2)\n",
    "model_2_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 20 \n",
    "knn_3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data\n",
    "knn_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[258  49]\n",
      " [ 75 116]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.84, The False Positive Rate is 0.26,\n",
      "    The True Negative Rate is 0.61, and the False Negative Rate is 0.24\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.840391</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.607330</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.738903</td>\n",
       "      <td>0.723860</td>\n",
       "      <td>0.728968</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.747258</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.774775  0.840391  0.806250  307.000000\n",
       "survived       0.703030  0.607330  0.651685  191.000000\n",
       "accuracy       0.751004  0.751004  0.751004    0.751004\n",
       "macro avg      0.738903  0.723860  0.728968  498.000000\n",
       "weighted avg   0.747258  0.751004  0.746969  498.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 3\n",
    "model_3_report = get_metrics_binary(knn_3)\n",
    "model_3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              precision    recall  f1-score     support\n",
       " died           0.849359  0.863192  0.856220  307.000000\n",
       " survived       0.774194  0.753927  0.763926  191.000000\n",
       " accuracy       0.821285  0.821285  0.821285    0.821285\n",
       " macro avg      0.811776  0.808559  0.810073  498.000000\n",
       " weighted avg   0.820530  0.821285  0.820822  498.000000,\n",
       "               precision    recall  f1-score     support\n",
       " died           0.823529  0.866450  0.844444  307.000000\n",
       " survived       0.765714  0.701571  0.732240  191.000000\n",
       " accuracy       0.803213  0.803213  0.803213    0.803213\n",
       " macro avg      0.794622  0.784010  0.788342  498.000000\n",
       " weighted avg   0.801355  0.803213  0.801410  498.000000,\n",
       "               precision    recall  f1-score     support\n",
       " died           0.774775  0.840391  0.806250  307.000000\n",
       " survived       0.703030  0.607330  0.651685  191.000000\n",
       " accuracy       0.751004  0.751004  0.751004    0.751004\n",
       " macro avg      0.738903  0.723860  0.728968  498.000000\n",
       " weighted avg   0.747258  0.751004  0.746969  498.000000)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_report, model_2_report, model_3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Takeaways:*** ###\n",
    "- Analysis applies only to in-sample data\n",
    "- All models beat the baseline precidiction model \n",
    "- Model 1 is the best model in terms of accuracy, 82%\n",
    "- Model 2 performs slightly worse than Model 1, but Accuracy drops off the most for model 3\n",
    "- It makes sense that the models with the smaller K perform better than the models with higher k values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy of KNN classifier on test set with k=5: 0.73\n",
      "-------------------------------------------\n",
      "Model 2 Accuracy of KNN classifier on test set with k=10: 0.74\n",
      "-------------------------------------------\n",
      "Model 3 Accuracy of KNN classifier on test set with k=20: 0.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 Accuracy of KNN classifier on test set with k=5: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))\n",
    "print('-------------------------------------------\\nModel 2 Accuracy of KNN classifier on test set with k=10: {:.2f}'\n",
    "     .format(knn_2.score(X_validate, y_validate)))\n",
    "print('-------------------------------------------\\nModel 3 Accuracy of KNN classifier on test set with k=20: {:.2f}\\n'\n",
    "     .format(knn_3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: Model 2 performs slightly better in terms of accuracy on the out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Try a KNN model where you limit the dimensionality of the Titanic Data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 5 \n",
    "knn_4 = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data and limit the dimensionality to 2 features\n",
    "knn_4.fit(X_train[['sex_male','fare']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_4.predict(X_train[['sex_male','fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_4.predict_proba(X_train[['sex_male','fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 50 141]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.74, and the False Negative Rate is 0.16\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.738220</td>\n",
       "      <td>0.754011</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.805881</td>\n",
       "      <td>0.800706</td>\n",
       "      <td>0.803050</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.814124</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.814473</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.841270  0.863192  0.852090  307.000000\n",
       "survived       0.770492  0.738220  0.754011  191.000000\n",
       "accuracy       0.815261  0.815261  0.815261    0.815261\n",
       "macro avg      0.805881  0.800706  0.803050  498.000000\n",
       "weighted avg   0.814124  0.815261  0.814473  498.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 4\n",
    "model_4_report = get_metrics_binary(knn_4)\n",
    "model_4_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does Model 4 perform on out of sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Accuracy of KNN classifier on validate(out of sample data set) with k=5: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Model 4 Accuracy of KNN classifier on validate(out of sample data set) with k=5: {:.2f}'\n",
    "     .format(knn_4.score(X_validate[['sex_male','fare']], y_validate)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
