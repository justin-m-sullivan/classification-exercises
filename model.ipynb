{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pydataset import data\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from env import host, user, password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_validate_test_split(df, target, seed=123):\n",
    "    '''\n",
    "    This function takes in a dataframe, the name of the target variable\n",
    "    (for stratification purposes), and an integer for a setting a seed\n",
    "    and splits the data into train, validate and test. \n",
    "    Test is 20% of the original dataset, validate is .30*.80= 24% of the \n",
    "    original dataset, and train is .70*.80= 56% of the original dataset. \n",
    "    The function returns, in this order, train, validate and test dataframes. \n",
    "    '''\n",
    "    train_validate, test = train_test_split(df, test_size=0.2, \n",
    "                                            random_state=seed, \n",
    "                                            stratify=df[target])\n",
    "    train, validate = train_test_split(train_validate, test_size=0.3, \n",
    "                                       random_state=seed,\n",
    "                                       stratify=train_validate[target])\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0           0             0         0       3    male  22.0      1      0   \n",
       "1           1             1         1       1  female  38.0      1      0   \n",
       "2           2             2         1       3  female  26.0      0      0   \n",
       "3           3             3         1       1  female  35.0      1      0   \n",
       "4           4             4         0       3    male  35.0      0      0   \n",
       "\n",
       "      fare embarked  class deck  embark_town  alone  \n",
       "0   7.2500        S  Third  NaN  Southampton      0  \n",
       "1  71.2833        C  First    C    Cherbourg      0  \n",
       "2   7.9250        S  Third  NaN  Southampton      1  \n",
       "3  53.1000        S  First    C  Southampton      0  \n",
       "4   8.0500        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic = get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    891 non-null    int64  \n",
      " 1   passenger_id  891 non-null    int64  \n",
      " 2   survived      891 non-null    int64  \n",
      " 3   pclass        891 non-null    int64  \n",
      " 4   sex           891 non-null    object \n",
      " 5   age           714 non-null    float64\n",
      " 6   sibsp         891 non-null    int64  \n",
      " 7   parch         891 non-null    int64  \n",
      " 8   fare          891 non-null    float64\n",
      " 9   embarked      889 non-null    object \n",
      " 10  class         891 non-null    object \n",
      " 11  deck          203 non-null    object \n",
      " 12  embark_town   889 non-null    object \n",
      " 13  alone         891 non-null    int64  \n",
      "dtypes: float64(2), int64(7), object(5)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preapare the data: Drop columns \n",
    "columns_to_drop = ['Unnamed: 0','pclass', 'embark_town', 'embarked', 'deck',  'parch', 'passenger_id', 'age']\n",
    "titanic.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex  sibsp     fare  class  alone\n",
       "0         0    male      1   7.2500  Third      0\n",
       "1         1  female      1  71.2833  First      0\n",
       "2         1  female      0   7.9250  Third      1\n",
       "3         1  female      1  53.1000  First      0\n",
       "4         0    male      0   8.0500  Third      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decode survived ==> This is the target variable and targets do not need to be encoded for classification decision trees\n",
    "titanic.rename(columns={'survived':\"survival\"}, inplace=True)\n",
    "titanic['survived'] = titanic.survival.apply(lambda n: 'survived' if n > 0 else 'died')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Class and Sex as these are features we want to explore. The additional features of fare, alone, sibsp are already encoded. \n",
    "dummies = pd.get_dummies(titanic[['class', 'sex']], drop_first=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat dummies df with Titanic \n",
    "titanic = pd.concat([titanic, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop additional columns after encoding\n",
    "titanic.drop(columns={'sex','class','survival'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, validate, and test\n",
    "#stratidfy by survived \n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target == survived\n",
    "#features == sex, class, fare, alone, siblings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "died        307\n",
       "survived    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determine the baseline prediction by finding the mode for survived\n",
    "train.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Establish baseline prediction\n",
    "train['baseline_prediction'] = 'died'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate baseline accuracy\n",
    "baseline_accuracy = (train.baseline_prediction == train.survived).mean()\n",
    "baseline_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up Model 1 Decision Tree with a max depth of 2\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the decision tree to training data\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check labels for class names\n",
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize decision tree: \n",
    "\n",
    "#import graphviz\n",
    "#from graphviz import Graph\n",
    "#\n",
    "#dot_data = export_graphviz(clf, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=clf.classes_)\n",
    "#graph = graphviz.Source(dot_data) \n",
    "#\n",
    "#graph.render('titanic_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'died', 'died', 'survived', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the first 5 predictions from model 1\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>baseline_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sibsp      fare  alone  survived  class_Second  class_Third  sex_male  \\\n",
       "583      0   40.1250      1      died             0            0         1   \n",
       "165      0   20.5250      0  survived             0            1         1   \n",
       "50       4   39.6875      0      died             0            1         1   \n",
       "259      0   26.0000      0  survived             1            0         0   \n",
       "306      0  110.8833      1  survived             0            0         0   \n",
       "\n",
       "    baseline_prediction  \n",
       "583                died  \n",
       "165                died  \n",
       "50                 died  \n",
       "259                died  \n",
       "306                died  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare the predictions against the actuals\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.68644068, 0.31355932],\n",
       "       [0.04255319, 0.95744681],\n",
       "       [0.04255319, 0.95744681]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the probabilities for each class\n",
    "y_pred_proba = clf.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "#Model Score: \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[265,  42],\n",
       "       [ 58, 133]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evealuate with Cofusion Matrix\n",
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>265</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>58</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          died  survived\n",
       "died       265        42\n",
       "survived    58       133"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.82      0.86      0.84       307\n",
      "    survived       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate with Classififcation Report\n",
    "model_1_report = classification_report(y_train, y_pred)\n",
    "print(model_1_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has an accuracy score of 79.92%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "print(f'Model has an accuracy score of {accuracy_score(y_pred, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate is: 53.21%\n",
      "False Positive Rate is: 11.65%\n",
      "True Negative Rate is: 26.71%\n",
      "False Negative Rate is: 8.43%\n"
     ]
    }
   ],
   "source": [
    "#Rates from confusions matrix \n",
    "#Where dead is being treated as the positive class and survived is the negative class\n",
    "\n",
    "sample_count = len(train)\n",
    "\n",
    "tp = 265\n",
    "fp = 58\n",
    "fn = 42\n",
    "tn = 133\n",
    "\n",
    "print(f'True Positive Rate is: {tp/sample_count:.2%}')\n",
    "print(f'False Positive Rate is: {fp/sample_count:.2%}')\n",
    "print(f'True Negative Rate is: {tn/sample_count:.2%}')\n",
    "print(f'False Negative Rate is: {fn/sample_count:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76      , 0.82043344])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Precision\n",
    "precision_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.69633508, 0.86319218])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recall\n",
    "recall_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72677596, 0.84126984])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f1-score\n",
    "f1_score(y_train, y_pred, labels=['survived', 'died'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([191, 307])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Support\n",
    "precision_recall_fscore_support(y_train, y_pred, labels=['survived', 'died'], average=None)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set-up Model 2 using a decision treet with a max depth of 3 \n",
    "clf_2 = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the training data to Model 2 \n",
    "clf_2 = clf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check labels\n",
    "clf_2.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the decision tree:\n",
    "\n",
    "#dot_data = export_graphviz(clf_2, feature_names= X_train.columns, rounded=True, filled=True, out_file=None, class_names=clf_2.classes_)\n",
    "#graph = graphviz.Source(dot_data) \n",
    "#\n",
    "#graph.render('titanic_2_decision_tree', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['died', 'died', 'died', 'survived', 'survived'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Peek at the first 5 predictions from model 2 \n",
    "y_pred_2 = clf_2.predict(X_train)\n",
    "y_pred_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.69827586, 0.30172414],\n",
       "       [0.69827586, 0.30172414],\n",
       "       [0.69827586, 0.30172414],\n",
       "       [0.07142857, 0.92857143],\n",
       "       [0.01923077, 0.98076923]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the probabilities for each class\n",
    "y_pred_proba = clf_2.predict_proba(X_train)\n",
    "y_pred_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on training set: 0.82\n"
     ]
    }
   ],
   "source": [
    "#Model 2 Score: \n",
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(clf_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[276,  31],\n",
       "       [ 57, 134]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evealuate with Cofusion Matrix\n",
    "confusion_matrix(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>died</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>276</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          died  survived\n",
       "died       276        31\n",
       "survived    57       134"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = sorted(y_train.unique())\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train, y_pred_2), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_report = classification_report(y_train, y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.83      0.90      0.86       307\n",
      "    survived       0.81      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_2_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Model 2 performs better on in-sample data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.82      0.86      0.84       307\n",
      "    survived       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        died       0.83      0.90      0.86       307\n",
      "    survived       0.81      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_1_report, model_2_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Model 2 performs better on the out-of-sample data***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 1 on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.76\n"
     ]
    }
   ],
   "source": [
    "#Model 1 Accuracy for Validate Data set\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.80      0.83      0.81       132\n",
      "    survived       0.70      0.66      0.68        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.75      0.74      0.74       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 2 on out-of-sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Model 2 Accuracy for Validate Data set\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf_2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = clf_2.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.80      0.87      0.83       132\n",
      "    survived       0.76      0.65      0.70        82\n",
      "\n",
      "    accuracy                           0.79       214\n",
      "   macro avg       0.78      0.76      0.77       214\n",
      "weighted avg       0.78      0.79      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_validate, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train, validate, test\n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "# create X & y version of train, where y is a series with just the target variable and X are all the features. \n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>survived</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>died</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>survived</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>survived</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sibsp      fare  alone  survived  class_Second  class_Third  sex_male\n",
       "583      0   40.1250      1      died             0            0         1\n",
       "165      0   20.5250      0  survived             0            1         1\n",
       "50       4   39.6875      0      died             0            1         1\n",
       "259      0   26.0000      0  survived             1            0         0\n",
       "306      0  110.8833      1  survived             0            0         0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.94\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "      <th>predict_death</th>\n",
       "      <th>predict_survive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_death</th>\n",
       "      <td>300</td>\n",
       "      <td>7</td>\n",
       "      <td>true positive</td>\n",
       "      <td>false negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_survive</th>\n",
       "      <td>23</td>\n",
       "      <td>168</td>\n",
       "      <td>false positive</td>\n",
       "      <td>true negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               predict_death predict_survive   predict_death predict_survive\n",
       "actual_death             300               7   true positive  false negative\n",
       "actual_survive            23             168  false positive   true negative"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])\n",
    "rubric_df = pd.DataFrame([['true positive', 'false negative'],['false positive', 'true negative']], columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])\n",
    "joined = pd.concat([conf_df, rubric_df], axis=1)\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        died       0.93      0.98      0.95       307\n",
      "    survived       0.96      0.88      0.92       191\n",
      "\n",
      "    accuracy                           0.94       498\n",
      "   macro avg       0.94      0.93      0.94       498\n",
      "weighted avg       0.94      0.94      0.94       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_binary(clf):\n",
    "    '''\n",
    "    get_metrics_binary takes in a confusion matrix (cnf) for a binary classifier and prints out metrics based on\n",
    "    values in variables named X_train, y_train, and y_pred.\n",
    "    \n",
    "    return: a classification report as a transposed DataFrame\n",
    "    '''\n",
    "    #accuracy = clf.score(X_train, y_train)\n",
    "    class_report = pd.DataFrame(classification_report(y_train, y_pred, output_dict=True)).T\n",
    "    clf = confusion_matrix(y_train, y_pred)\n",
    "    tpr = clf[0][0] / clf[0].sum()\n",
    "    fpr = clf[0][1] / clf[1].sum()\n",
    "    tnr = clf[1][1] / clf[1].sum()\n",
    "    fnr = clf[1][0] / clf[0].sum()\n",
    "    print(f'''\n",
    "    Confusion Matrix: \\n {clf},\n",
    "    '--------------------------------',\n",
    "    The True Positive Rate is {tpr:.2}, The False Positive Rate is {fpr:.2},\n",
    "    The True Negative Rate is {tnr:.2}, and the False Negative Rate is {fnr:.2}\n",
    "    ''')\n",
    "    return class_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.98, The False Positive Rate is 0.037,\n",
      "    The True Negative Rate is 0.88, and the False Negative Rate is 0.075\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.928793</td>\n",
       "      <td>0.977199</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.879581</td>\n",
       "      <td>0.918033</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.944396</td>\n",
       "      <td>0.928390</td>\n",
       "      <td>0.935207</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.940762</td>\n",
       "      <td>0.939759</td>\n",
       "      <td>0.939207</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.928793  0.977199  0.952381  307.000000\n",
       "survived       0.960000  0.879581  0.918033  191.000000\n",
       "accuracy       0.939759  0.939759  0.939759    0.939759\n",
       "macro avg      0.944396  0.928390  0.935207  498.000000\n",
       "weighted avg   0.940762  0.939759  0.939207  498.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model1_report = get_metrics_binary(conf_df)\n",
    "rf_model1_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model 2 with increased min_samples_leaf and decreased mx_depth\n",
    "rf_2 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=2,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=4, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=4, min_samples_leaf=2, random_state=123)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the training data to random forest model 2\n",
    "rf_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the y_pred\n",
    "y_pred = rf_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 Accuracy of random forest classifier on training set: 0.84\n"
     ]
    }
   ],
   "source": [
    "#Return accuracy metric for random forest model 2\n",
    "print('Model 2 Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf_2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the confusion matrix for model 2...treat death as the positive class\n",
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.94, The False Positive Rate is 0.099,\n",
      "    The True Negative Rate is 0.68, and the False Negative Rate is 0.2\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.938111</td>\n",
       "      <td>0.876712</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.871622</td>\n",
       "      <td>0.675393</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.837349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.847239</td>\n",
       "      <td>0.806752</td>\n",
       "      <td>0.818887</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.841560</td>\n",
       "      <td>0.837349</td>\n",
       "      <td>0.832356</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.822857  0.938111  0.876712  307.000000\n",
       "survived       0.871622  0.675393  0.761062  191.000000\n",
       "accuracy       0.837349  0.837349  0.837349    0.837349\n",
       "macro avg      0.847239  0.806752  0.818887  498.000000\n",
       "weighted avg   0.841560  0.837349  0.832356  498.000000"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return metrics report for evaluating model 2 \n",
    "rf_model2_report = get_metrics_binary(conf_df)\n",
    "rf_model2_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Random Forest Metrics: \n",
      "\n",
      "               precision    recall  f1-score     support\n",
      "died           0.928793  0.977199  0.952381  307.000000\n",
      "survived       0.960000  0.879581  0.918033  191.000000\n",
      "accuracy       0.939759  0.939759  0.939759    0.939759\n",
      "macro avg      0.944396  0.928390  0.935207  498.000000\n",
      "weighted avg   0.940762  0.939759  0.939207  498.000000\n",
      "--------------------------------------\n",
      "Model 2 Random Forest Metrics: \n",
      "\n",
      "               precision    recall  f1-score     support\n",
      "died           0.822857  0.938111  0.876712  307.000000\n",
      "survived       0.871622  0.675393  0.761062  191.000000\n",
      "accuracy       0.837349  0.837349  0.837349    0.837349\n",
      "macro avg      0.847239  0.806752  0.818887  498.000000\n",
      "weighted avg   0.841560  0.837349  0.832356  498.000000\n"
     ]
    }
   ],
   "source": [
    "print(f'Model 1 Random Forest Metrics: \\n\\n {rf_model1_report:}')\n",
    "print('--------------------------------------')\n",
    "print(f'Model 2 Random Forest Metrics: \\n\\n {rf_model2_report:}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Model 3 with increased min_samples_leaf and decreased mx_depth\n",
    "rf_3 = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=10,\n",
    "                            n_estimators=100,\n",
    "                            max_depth=8, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3.fit(X_train, y_train)\n",
    "y_pred = rf_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.83\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf_3.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = (confusion_matrix(y_train, y_pred))\n",
    "conf_df = pd.DataFrame(conf_matrix, columns=['predict_death', 'predict_survive'], index=['actual_death', 'actual_survive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The True Positive Rate is 0.95, The False Positive Rate is 0.084,\n",
      "    The True Negative Rate is 0.63, and the False Negative Rate is 0.23\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.806094</td>\n",
       "      <td>0.947883</td>\n",
       "      <td>0.871257</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.883212</td>\n",
       "      <td>0.633508</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.827309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.844653</td>\n",
       "      <td>0.790695</td>\n",
       "      <td>0.804531</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.835671</td>\n",
       "      <td>0.827309</td>\n",
       "      <td>0.820074</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.806094  0.947883  0.871257  307.000000\n",
       "survived       0.883212  0.633508  0.737805  191.000000\n",
       "accuracy       0.827309  0.827309  0.827309    0.827309\n",
       "macro avg      0.844653  0.790695  0.804531  498.000000\n",
       "weighted avg   0.835671  0.827309  0.820074  498.000000"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model3_report = get_metrics_binary(conf_matrix)\n",
    "rf_model3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Random Forest Model 1 performs the best on the training data set***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the models with out of sample data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy of random forest classifier on validate set: 0.78\n",
      "------------\n",
      "Model 2 Accuracy of random forest classifier on validate set: 0.79\n",
      "------------\n",
      "Model 3 Accuracy of random forest classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf.predict(X_validate)\n",
    "print('Model 1 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf.score(X_validate, y_validate)))\n",
    "\n",
    "print('------------')\n",
    "y_pred = rf_2.predict(X_validate)\n",
    "print('Model 2 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf_2.score(X_validate, y_validate)))\n",
    "\n",
    "print('------------')\n",
    "y_pred = rf_3.predict(X_validate)\n",
    "print('Model 3 Accuracy of random forest classifier on validate set: {:.2f}'\n",
    "     .format(rf_3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: ***Random Forest Model 1 performs better on the validate data set***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sibsp         498 non-null    int64  \n",
      " 1   fare          498 non-null    float64\n",
      " 2   alone         498 non-null    int64  \n",
      " 3   survived      498 non-null    object \n",
      " 4   class_Second  498 non-null    uint8  \n",
      " 5   class_Third   498 non-null    uint8  \n",
      " 6   sex_male      498 non-null    uint8  \n",
      "dtypes: float64(1), int64(2), object(1), uint8(3)\n",
      "memory usage: 20.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#Confirm training data set is good to work with\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k=5\n",
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data without limiting the dimensions (using all features for this model)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [0.4, 0.6],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0. , 1. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0.6, 0.4],\n",
       "       [0.4, 0.6],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.6, 0.4],\n",
       "       [0. , 1. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.4, 0.6],\n",
       "       [0.8, 0.2],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [0. , 1. ],\n",
       "       [1. , 0. ],\n",
       "       [0.2, 0.8],\n",
       "       [1. , 0. ],\n",
       "       [0.8, 0.2],\n",
       "       [1. , 0. ],\n",
       "       [0.6, 0.4],\n",
       "       [0.8, 0.2]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 47 144]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.75, and the False Negative Rate is 0.15\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.849359</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.856220</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.810073</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820530</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.820822</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.849359  0.863192  0.856220  307.000000\n",
       "survived       0.774194  0.753927  0.763926  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.811776  0.808559  0.810073  498.000000\n",
       "weighted avg   0.820530  0.821285  0.820822  498.000000"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_metrics_binary(knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 47 144]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.75, and the False Negative Rate is 0.15\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.849359</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.856220</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.753927</td>\n",
       "      <td>0.763926</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.821285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.811776</td>\n",
       "      <td>0.808559</td>\n",
       "      <td>0.810073</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.820530</td>\n",
       "      <td>0.821285</td>\n",
       "      <td>0.820822</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.849359  0.863192  0.856220  307.000000\n",
       "survived       0.774194  0.753927  0.763926  191.000000\n",
       "accuracy       0.821285  0.821285  0.821285    0.821285\n",
       "macro avg      0.811776  0.808559  0.810073  498.000000\n",
       "weighted avg   0.820530  0.821285  0.820822  498.000000"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_report = get_metrics_binary(knn)\n",
    "model_1_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 setting k to 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 10 \n",
    "knn_2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data\n",
    "knn_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[266  41]\n",
      " [ 57 134]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.87, The False Positive Rate is 0.21,\n",
      "    The True Negative Rate is 0.7, and the False Negative Rate is 0.19\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.866450</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.765714</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.732240</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.803213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.794622</td>\n",
       "      <td>0.784010</td>\n",
       "      <td>0.788342</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.801355</td>\n",
       "      <td>0.803213</td>\n",
       "      <td>0.801410</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.823529  0.866450  0.844444  307.000000\n",
       "survived       0.765714  0.701571  0.732240  191.000000\n",
       "accuracy       0.803213  0.803213  0.803213    0.803213\n",
       "macro avg      0.794622  0.784010  0.788342  498.000000\n",
       "weighted avg   0.801355  0.803213  0.801410  498.000000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 2\n",
    "model_2_report = get_metrics_binary(knn_2)\n",
    "model_2_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Run through setps 2-4 setting k to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 20 \n",
    "knn_3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data\n",
    "knn_3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_3.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[258  49]\n",
      " [ 75 116]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.84, The False Positive Rate is 0.26,\n",
      "    The True Negative Rate is 0.61, and the False Negative Rate is 0.24\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.840391</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.703030</td>\n",
       "      <td>0.607330</td>\n",
       "      <td>0.651685</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.751004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.738903</td>\n",
       "      <td>0.723860</td>\n",
       "      <td>0.728968</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.747258</td>\n",
       "      <td>0.751004</td>\n",
       "      <td>0.746969</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.774775  0.840391  0.806250  307.000000\n",
       "survived       0.703030  0.607330  0.651685  191.000000\n",
       "accuracy       0.751004  0.751004  0.751004    0.751004\n",
       "macro avg      0.738903  0.723860  0.728968  498.000000\n",
       "weighted avg   0.747258  0.751004  0.746969  498.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 3\n",
    "model_3_report = get_metrics_binary(knn_3)\n",
    "model_3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              precision    recall  f1-score     support\n",
       " died           0.849359  0.863192  0.856220  307.000000\n",
       " survived       0.774194  0.753927  0.763926  191.000000\n",
       " accuracy       0.821285  0.821285  0.821285    0.821285\n",
       " macro avg      0.811776  0.808559  0.810073  498.000000\n",
       " weighted avg   0.820530  0.821285  0.820822  498.000000,\n",
       "               precision    recall  f1-score     support\n",
       " died           0.823529  0.866450  0.844444  307.000000\n",
       " survived       0.765714  0.701571  0.732240  191.000000\n",
       " accuracy       0.803213  0.803213  0.803213    0.803213\n",
       " macro avg      0.794622  0.784010  0.788342  498.000000\n",
       " weighted avg   0.801355  0.803213  0.801410  498.000000,\n",
       "               precision    recall  f1-score     support\n",
       " died           0.774775  0.840391  0.806250  307.000000\n",
       " survived       0.703030  0.607330  0.651685  191.000000\n",
       " accuracy       0.751004  0.751004  0.751004    0.751004\n",
       " macro avg      0.738903  0.723860  0.728968  498.000000\n",
       " weighted avg   0.747258  0.751004  0.746969  498.000000)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_report, model_2_report, model_3_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Takeaways:*** ###\n",
    "- Analysis applies only to in-sample data\n",
    "- All models beat the baseline precidiction model \n",
    "- Model 1 is the best model in terms of accuracy, 82%\n",
    "- Model 2 performs slightly worse than Model 1, but Accuracy drops off the most for model 3\n",
    "- It makes sense that the models with the smaller K perform better than the models with higher k values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Accuracy of KNN classifier on test set with k=5: 0.73\n",
      "-------------------------------------------\n",
      "Model 2 Accuracy of KNN classifier on test set with k=10: 0.74\n",
      "-------------------------------------------\n",
      "Model 3 Accuracy of KNN classifier on test set with k=20: 0.68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Model 1 Accuracy of KNN classifier on test set with k=5: {:.2f}'\n",
    "     .format(knn.score(X_validate, y_validate)))\n",
    "print('-------------------------------------------\\nModel 2 Accuracy of KNN classifier on test set with k=10: {:.2f}'\n",
    "     .format(knn_2.score(X_validate, y_validate)))\n",
    "print('-------------------------------------------\\nModel 3 Accuracy of KNN classifier on test set with k=20: {:.2f}\\n'\n",
    "     .format(knn_3.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway: Model 2 performs slightly better in terms of accuracy on the out-of-sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: Try a KNN model where you limit the dimensionality of the Titanic Data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a KNN model with k set to 5 \n",
    "knn_4 = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model to the training data and limit the dimensionality to 2 features\n",
    "knn_4.fit(X_train[['sex_male','fare']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred = knn_4.predict(X_train[['sex_male','fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate the probability for each class (died, survived)\n",
    "y_pred_proba = knn_4.predict_proba(X_train[['sex_male','fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Confusion Matrix: \n",
      " [[265  42]\n",
      " [ 50 141]],\n",
      "    '--------------------------------',\n",
      "    The True Positive Rate is 0.86, The False Positive Rate is 0.22,\n",
      "    The True Negative Rate is 0.74, and the False Negative Rate is 0.16\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>died</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.863192</td>\n",
       "      <td>0.852090</td>\n",
       "      <td>307.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.738220</td>\n",
       "      <td>0.754011</td>\n",
       "      <td>191.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.815261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.805881</td>\n",
       "      <td>0.800706</td>\n",
       "      <td>0.803050</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.814124</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.814473</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "died           0.841270  0.863192  0.852090  307.000000\n",
       "survived       0.770492  0.738220  0.754011  191.000000\n",
       "accuracy       0.815261  0.815261  0.815261    0.815261\n",
       "macro avg      0.805881  0.800706  0.803050  498.000000\n",
       "weighted avg   0.814124  0.815261  0.814473  498.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Evaluate KNN Model 4\n",
    "model_4_report = get_metrics_binary(knn_4)\n",
    "model_4_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does Model 4 perform on out of sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 4 Accuracy of KNN classifier on validate(out of sample data set) with k=5: 0.75\n"
     ]
    }
   ],
   "source": [
    "print('Model 4 Accuracy of KNN classifier on validate(out of sample data set) with k=5: {:.2f}'\n",
    "     .format(knn_4.score(X_validate[['sex_male','fare']], y_validate)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "\n",
    "For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from env import host, user, password\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acquire import get_titanic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preapare the data: Drop columns \n",
    "columns_to_drop = ['Unnamed: 0', 'embark_town', 'embarked', 'deck',  'parch', 'passenger_id', 'class']\n",
    "titanic.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode the feature \"sex\"\n",
    "df = pd.get_dummies(titanic[['sex']], drop_first=[True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat dummies df with Titanic and drop the original coloumn sex\n",
    "titanic = pd.concat([titanic, dummies], axis=1).drop(columns='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp     fare  alone  class_Second  class_Third  \\\n",
       "0         0       3  22.0      1   7.2500      0             0            1   \n",
       "1         1       1  38.0      1  71.2833      0             0            0   \n",
       "2         1       3  26.0      0   7.9250      1             0            1   \n",
       "3         1       1  35.0      1  53.1000      0             0            0   \n",
       "4         0       3  35.0      0   8.0500      1             0            1   \n",
       "\n",
       "   sex_male  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   survived      891 non-null    int64  \n",
      " 1   pclass        891 non-null    int64  \n",
      " 2   age           714 non-null    float64\n",
      " 3   sibsp         891 non-null    int64  \n",
      " 4   fare          891 non-null    float64\n",
      " 5   alone         891 non-null    int64  \n",
      " 6   class_Second  891 non-null    uint8  \n",
      " 7   class_Third   891 non-null    uint8  \n",
      " 8   sex_male      891 non-null    uint8  \n",
      "dtypes: float64(2), int64(4), uint8(3)\n",
      "memory usage: 44.5 KB\n"
     ]
    }
   ],
   "source": [
    "titanic.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To determine how to best deal with missing age values:\n",
    "- How many observations are missing age?\n",
    "    - Do the observations missing age have other features in common that could assist with filling those values?\n",
    "    - Should I fill missing values or drop those observations? \n",
    "- What does the distribution of age look like?\n",
    "- Is there a relationship between age and the number of siblings?\n",
    "    - If you had a sibling on the Titanic, were you more likely to be a child? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='age', ylabel='Count'>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAASGUlEQVR4nO3dfZBddX3H8fcHVkRANCkLE0PS4DRVKFPRrsqDY61oResItiI41WY6tNipCD6MDtSZWqdjxz8cR6etltSnVC2KiIK0g2AAO2qLLg9qMCLWBxISyar1oeqokW//uCeHK92QzW7uPSe579fMnXPP796b/WTZ8NnfOef+bqoKSZIADuo6gCSpPywFSVLLUpAktSwFSVLLUpAktaa6DrAURx11VK1Zs6brGJK0X7nlllu+U1XT8z22X5fCmjVrmJ2d7TqGJO1Xknxrd495+EiS1BpZKSR5d5IdSTYNjS1Pcn2Su5rtsqHHLknytSR3JnnWqHJJknZvlDOF9wJnPGDsYmBjVa0FNjb7JDkBOBf4reY1b09y8AizSZLmMbJSqKr/AL73gOEzgQ3N/Q3AWUPjH6yqn1XVN4CvAU8aVTZJ0vzGfU7hmKraDtBsj27GVwJbhp63tRn7f5Kcn2Q2yezc3NxIw0rSpOnLiebMMzbvSn1Vtb6qZqpqZnp63iuqJEmLNO5SuDfJCoBmu6MZ3wqsGnrescC2MWeTpIk37lK4GljX3F8HXDU0fm6ShyY5DlgLfG7M2SRp4o3szWtJLgOeBhyVZCvweuBNwOVJzgPuBs4GqKo7klwOfBnYCbysqn45qmySpPmNrBSq6kW7eej03Tz/jcAbR5VHS7dy1Wq2bd2y5yfO41HHruKeLXfv40SS9rX9epkLjde2rVs459LPLuq1H3rpqfs4jaRR6MvVR5KkHrAUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUJEktS0GS1LIUNB4HTZFkUbeVq1Z3nV6aGFNdB9CEuG8n51z62UW99EMvPXUfh5G0O84U1H/OMqSxcaag/nOWIY2NMwVJUstSkCS1LAVJUstSkCS1OimFJK9MckeSTUkuS3JokuVJrk9yV7Nd1kU2SZpkYy+FJCuBC4GZqjoROBg4F7gY2FhVa4GNzb4kaYy6Onw0BTwsyRRwGLANOBPY0Dy+ATirm2iSNLnGXgpVdQ/wZuBuYDvwg6q6DjimqrY3z9kOHD3f65Ocn2Q2yezc3Ny4YkvSROji8NEyBrOC44BHAYcnefFCX19V66tqpqpmpqenRxVTkiZSF4ePngF8o6rmquoXwJXAqcC9SVYANNsdHWQ7oK1ctXrRy0Uk6Tq+pDHoYpmLu4GTkxwG/BQ4HZgFfgysA97UbK/qINsBbdvWLYteLgJcMkKaBGMvhaq6OckVwK3ATuA2YD1wBHB5kvMYFMfZ484mSZOukwXxqur1wOsfMPwzBrMGSVJHfEezJKllKUiSWpaCJKllKUiSWpaCJKllKUiSWpaCJKllKUiSWpaCJKllKejAdtDUkhYBXLlqddd/A2msOlnmQhqb+3a6CKC0F5wpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJaloIkqdVJKSR5ZJIrknwlyeYkpyRZnuT6JHc122VdZJOkSdbVTOFtwLVV9VjgccBm4GJgY1WtBTY2+5KkMRp7KSQ5Engq8C6Aqvp5VX0fOBPY0DxtA3DWuLNJ0qTrYqbwaGAOeE+S25K8M8nhwDFVtR2g2R4934uTnJ9kNsns3Nzc+FJL0gToohSmgCcA76iqxwM/Zi8OFVXV+qqaqaqZ6enpUWWUpInURSlsBbZW1c3N/hUMSuLeJCsAmu2ODrJJ0kQbeylU1beBLUke0wydDnwZuBpY14ytA64adzZJmnRTHX3dlwMfSHII8HXgTxkU1OVJzgPuBs7uKJskTaxOSqGqbgdm5nno9DFHkSQNWdDhoySnLWRMkrR/W+g5hb9f4JgkaT/2oIePkpwCnApMJ3nV0ENHAgePMpgkafz2dE7hEOCI5nkPHxr/IfCCUYWSJHXjQUuhqj4FfCrJe6vqW2PKJEnqyEKvPnpokvXAmuHXVNXTRxFKktSNhZbCh4F/At4J/HJ0cSRJXVpoKeysqneMNIkkqXMLvST140n+MsmK5sNwlidZPtJkkqSxW+hMYdeaRK8ZGisGy2BLkg4QCyqFqjpu1EEkSd1bUCkk+ZP5xqvqX/ZtHElSlxZ6+OiJQ/cPZbBw3a2ApSBJB5CFHj56+fB+kkcA7xtJIklSZxb7ITs/AdbuyyCSpO4t9JzCxxlcbQSDhfCOBy4fVShJUjcWek7hzUP3dwLfqqqtI8gjSerQgg4fNQvjfYXBSqnLgJ+PMpQkqRsL/eS1FwKfY/C5yS8Ebk7i0tmSdIBZ6OGj1wFPrKodAEmmgU8CV4wqmCRp/BZ69dFBuwqh8d29eK0kaT+x0JnCtUk+AVzW7J8D/PtoIkmSurKnz2j+DeCYqnpNkj8EngIE+E/gA2PIJ0kaoz0dAnor8COAqrqyql5VVa9kMEt462ijSZLGbU+lsKaqvvjAwaqaZfDRnJKkA8ieSuHQB3nsYfsyiCSpe3sqhc8n+fMHDiY5D7hlNJGkHjloiiSLuq1ctbrr9NJe29PVR68APprkj7m/BGaAQ4DnjzCX1A/37eScSz+7qJd+6KWn7uMw0ug9aClU1b3AqUl+DzixGf63qrph5MkkSWO30M9TuBG4ccRZJEkd813JkqSWpSBJalkKkqRWZ6WQ5OAktyW5ptlfnuT6JHc122VdZZOkSdXlTOEiYPPQ/sXAxqpaC2xs9iVJY9RJKSQ5FvgD4J1Dw2cCG5r7G4CzxhxLkiZeVzOFtwKvBe4bGjumqrYDNNuj53thkvOTzCaZnZubW1KIlatW+25VSRqy0M9T2GeSPBfYUVW3JHna3r6+qtYD6wFmZmZqKVm2bd3iu1UlacjYSwE4DXhekucwWHDvyCTvB+5NsqKqtidZAex40D9FkrTPjf3wUVVdUlXHVtUa4Fzghqp6MXA1sK552jrgqnFnk6RJ16f3KbwJeGaSu4BnNvuSpDHq4vBRq6puAm5q7n8XOL3LPJI06fo0U5AkdcxSkCS1LAVJUstSkCS1LAVJUstSkEbloKlFL6MydcihLsGiTnR6Sap0QLtv55KWUXEJFnXBmYIkqWUpSJJaloIkqWUpSJJaloIkqWUpSJJalsJ+ZikfISpJe+L7FPYzfoSopFFypiBJalkKkqSWpSBJalkK0oFmCQvxuZiePNEsHWiWuBCfJpszBUlSy1KQJLUsBUlSy1KQJLUsBUlSy1KQJLUsBUlSy1KQJLUsBUlSy1KQJLUsBUlSy1KQJLUsBUlSa+ylkGRVkhuTbE5yR5KLmvHlSa5PclezXTbubJI06bqYKewEXl1VxwMnAy9LcgJwMbCxqtYCG5t9SdIYjb0Uqmp7Vd3a3P8RsBlYCZwJbGietgE4a9zZJGnSdXpOIcka4PHAzcAxVbUdBsUBHN1hNEmaSJ2VQpIjgI8Ar6iqH+7F685PMptkdm5ubnQBJWkCdVIKSR7CoBA+UFVXNsP3JlnRPL4C2DHfa6tqfVXNVNXM9PT0eAJL0oTo4uqjAO8CNlfVW4YeuhpY19xfB1w17mySNOmmOviapwEvAb6U5PZm7K+ANwGXJzkPuBs4u4NskjTRxl4KVfVpILt5+PRxZpEk/Srf0SxJalkKkqSWpSBJalkKku530BRJFn1buWp1138DLVEXVx9J6qv7dnLOpZ9d9Ms/9NJT92EYdcGZQgdWrlq96N/EJGmUnCl0YNvWLYv+bczfxCSNkqWwWM2xV0k6kFgKi7WEY6/+ti+przynIGnfWcLVS1651A/OFCTtO86g93vOFCRJLUtBktSyFCRJLUtBUj94kroXPNEsqR88Sd0LzhQkSS1LQZLUshQkSS1LQZLUshQkSS1LQZLUshQkSS1LQZLUshQkSS1LQZLUshQkTbSVq1a75tIQ1z6SNNG2bd3imktDLAVJ+79mhVUtnaUgaf/nCqv7jOcUJEktS0GS1LIUJEktS0GS1OpdKSQ5I8mdSb6W5OKu80jSJOlVKSQ5GPhH4NnACcCLkpzQbSpJ2o3mUtjF3qYOObR3b5zr2yWpTwK+VlVfB0jyQeBM4MudppKk+SzhUlgYXA7bt0tpU1Uj+YMXI8kLgDOq6s+a/ZcAT66qC4aecz5wfrP7GODORXypo4DvLDHuKJhr7/U1m7n2Tl9zQX+zLSXXr1fV9HwP9G2mMN9bEn+ltapqPbB+SV8kma2qmaX8GaNgrr3X12zm2jt9zQX9zTaqXL06pwBsBVYN7R8LbOsoiyRNnL6VwueBtUmOS3IIcC5wdceZJGli9OrwUVXtTHIB8AngYODdVXXHCL7Ukg4/jZC59l5fs5lr7/Q1F/Q320hy9epEsySpW307fCRJ6pClIElqTVQp9GkJjSTvTrIjyaahseVJrk9yV7Nd1kGuVUluTLI5yR1JLupDtiSHJvlcki80ud7Qh1xD+Q5OcluSa3qW65tJvpTk9iSzfcmW5JFJrkjyleZn7ZSucyV5TPN92nX7YZJXdJ2ryfbK5ud+U5LLmn8PI8k1MaWQ/i2h8V7gjAeMXQxsrKq1wMZmf9x2Aq+uquOBk4GXNd+nrrP9DHh6VT0OOAk4I8nJPci1y0XA5qH9vuQC+L2qOmnomvY+ZHsbcG1VPRZ4HIPvXae5qurO5vt0EvA7wE+Aj3adK8lK4EJgpqpOZHARzrkjy1VVE3EDTgE+MbR/CXBJx5nWAJuG9u8EVjT3VwB39uD7dhXwzD5lAw4DbgWe3IdcDN5PsxF4OnBNn/5bAt8EjnrAWKfZgCOBb9Bc6NKXXA/I8vvAZ/qQC1gJbAGWM7hi9Jom30hyTcxMgfu/sbtsbcb65Jiq2g7QbI/uMkySNcDjgZvpQbbmEM3twA7g+qrqRS7grcBrgfuGxvqQCwYrAlyX5JZmiZg+ZHs0MAe8pznk9s4kh/cg17Bzgcua+53mqqp7gDcDdwPbgR9U1XWjyjVJpbDHJTR0vyRHAB8BXlFVP+w6D0BV/bIGU/tjgSclObHjSCR5LrCjqm7pOstunFZVT2Bw2PRlSZ7adSAGv+0+AXhHVT0e+DHdHl77Fc0bZ58HfLjrLADNuYIzgeOARwGHJ3nxqL7eJJXC/rCExr1JVgA02x1dhEjyEAaF8IGqurJP2QCq6vvATQzOyXSd6zTgeUm+CXwQeHqS9/cgFwBVta3Z7mBwfPxJPci2FdjazPQArmBQEl3n2uXZwK1VdW+z33WuZwDfqKq5qvoFcCVw6qhyTVIp7A9LaFwNrGvur2NwPH+skgR4F7C5qt7Sl2xJppM8srn/MAb/UL7Sda6quqSqjq2qNQx+pm6oqhd3nQsgyeFJHr7rPoPj0Ju6zlZV3wa2JHlMM3Q6g+XxO/+eNV7E/YeOoPtcdwMnJzms+fd5OoMT86PJ1dWJnC5uwHOArwL/Dbyu4yyXMTg++AsGvzmdB/wagxOWdzXb5R3kegqDw2pfBG5vbs/pOhvw28BtTa5NwF83451/z4YyPo37TzR3novBsfsvNLc7dv3M9yTbScBs89/zY8CynuQ6DPgu8IihsT7kegODX4I2Ae8DHjqqXC5zIUlqTdLhI0nSHlgKkqSWpSBJalkKkqSWpSBJalkKkqSWpSBJalkK0iIl+Viz0NwduxabS3Jekq8muSnJPyf5h2Z8OslHkny+uZ3WbXppfr55TVqkJMur6nvNshufB54FfIbBOj4/Am4AvlBVFyT5V+DtVfXpJKsZLON+fGfhpd2Y6jqAtB+7MMnzm/urgJcAn6qq7wEk+TDwm83jzwBOGCxdA8CRSR5eVT8aZ2BpTywFaRGSPI3B/+hPqaqfJLmJwYee7O63/4Oa5/50LAGlRfKcgrQ4jwD+pymExzL46NLDgN9NsizJFPBHQ8+/Drhg106Sk8YZVlooS0FanGuBqSRfBP4W+C/gHuDvGHxS3ScZLAf9g+b5FwIzSb6Y5MvAX4w/srRnnmiW9qEkR1TV/zYzhY8C766qj3adS1ooZwrSvvU3zedIb2Lw4fQf6zSNtJecKUiSWs4UJEktS0GS1LIUJEktS0GS1LIUJEmt/wPT3ofJHrfU8QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the distribution of age\n",
    "sns.histplot(titanic.age[titanic.age.notnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many nulls in age: \n",
    "null_age = titanic.age.isnull().sum()\n",
    "null_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19865319865319866"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What % of the observations are missing age?\n",
    "null_age/len(titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    survived  pclass  age  sibsp     fare  alone  class_Second  class_Third  \\\n",
       "5          0       3  NaN      0   8.4583      1             0            1   \n",
       "17         1       2  NaN      0  13.0000      1             1            0   \n",
       "19         1       3  NaN      0   7.2250      1             0            1   \n",
       "26         0       3  NaN      0   7.2250      1             0            1   \n",
       "28         1       3  NaN      0   7.8792      1             0            1   \n",
       "\n",
       "    sex_male  \n",
       "5          1  \n",
       "17         1  \n",
       "19         0  \n",
       "26         1  \n",
       "28         0  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter all the passengers with missing ages for exploration\n",
    "passengers_no_age = titanic[titanic.age.isnull()]\n",
    "passengers_no_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x7fbdc5127820>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1620x1620 with 90 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visuaize the features for those passengers with missing ages\n",
    "sns.pairplot(data=passengers_no_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways for passengers with no documented ages: \n",
    "- Of those with missing ages, 2x as likely to die \n",
    "- Majority with no documented age were in 3rd class\n",
    "- Most did not have any siblings\n",
    "- 2/3 travelled alone\n",
    "- 2x were males\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    243.000000\n",
       "mean      26.407078\n",
       "std       15.603758\n",
       "min        0.670000\n",
       "25%       16.000000\n",
       "50%       26.000000\n",
       "75%       37.000000\n",
       "max       70.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Population stats for passengers' ages with at least 1 siblings\n",
    "titanic.age[titanic.sibsp > 0].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    471.000000\n",
       "mean      31.397558\n",
       "std       13.647767\n",
       "min        0.420000\n",
       "25%       22.000000\n",
       "50%       29.000000\n",
       "75%       39.000000\n",
       "max       80.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Population stats for passengers' ages that did not have any siblings\n",
    "titanic.age[titanic.sibsp == 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Decision Time:\n",
    "- Because there is not enough evudence from other festures to infer a best age imputer, I will drop all rows and onbservations with missing ages.\n",
    "- This will result in a 20% loss of obersevations, but I am under the assumption that less data here will be less impactful on the model than incorrect data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp     fare  alone  class_Second  class_Third  \\\n",
       "0         0       3  22.0      1   7.2500      0             0            1   \n",
       "1         1       1  38.0      1  71.2833      0             0            0   \n",
       "2         1       3  26.0      0   7.9250      1             0            1   \n",
       "3         1       1  35.0      1  53.1000      0             0            0   \n",
       "4         0       3  35.0      0   8.0500      1             0            1   \n",
       "\n",
       "   sex_male  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop observations with missing age\n",
    "titanic = titanic[titanic.age.notnull()]\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, validate, and test\n",
    "#stratidfy by survived \n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp     fare  alone  class_Second  class_Third  \\\n",
       "652         0       3  21.0      0   8.4333      1             0            1   \n",
       "813         0       3   6.0      4  31.2750      0             0            1   \n",
       "194         1       1  44.0      0  27.7208      1             0            0   \n",
       "417         1       2  18.0      0  13.0000      0             1            0   \n",
       "460         1       1  48.0      0  26.5500      1             0            0   \n",
       "\n",
       "     sex_male  \n",
       "652         1  \n",
       "813         0  \n",
       "194         0  \n",
       "417         0  \n",
       "460         1  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object\n",
    "logit = LogisticRegression(C=1, class_weight=None, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit.fit(X_train[['age','fare','pclass']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.04138191  0.00146339 -1.19226315]]\n",
      "Intercept: \n",
      " [3.42691873]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit.coef_)\n",
    "print('Intercept: \\n', logit.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = logit.predict(X_train[['age','fare','pclass']])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.73234435, 0.26765565],\n",
       "       [0.58719813, 0.41280187],\n",
       "       [0.38831084, 0.61168916],\n",
       "       [0.42151867, 0.57848133],\n",
       "       [0.42869509, 0.57130491],\n",
       "       [0.63028828, 0.36971172],\n",
       "       [0.60092194, 0.39907806],\n",
       "       [0.73249013, 0.26750987],\n",
       "       [0.42697976, 0.57302024],\n",
       "       [0.55411812, 0.44588188],\n",
       "       [0.87212214, 0.12787786],\n",
       "       [0.60785499, 0.39214501],\n",
       "       [0.28485315, 0.71514685],\n",
       "       [0.7158947 , 0.2841053 ],\n",
       "       [0.63603063, 0.36396937],\n",
       "       [0.52521243, 0.47478757],\n",
       "       [0.54512485, 0.45487515],\n",
       "       [0.87641324, 0.12358676],\n",
       "       [0.299683  , 0.700317  ],\n",
       "       [0.66175815, 0.33824185],\n",
       "       [0.49328319, 0.50671681],\n",
       "       [0.50769458, 0.49230542],\n",
       "       [0.81021521, 0.18978479],\n",
       "       [0.84243401, 0.15756599],\n",
       "       [0.59385051, 0.40614949],\n",
       "       [0.2327083 , 0.7672917 ],\n",
       "       [0.95503888, 0.04496112],\n",
       "       [0.33124381, 0.66875619],\n",
       "       [0.24646001, 0.75353999],\n",
       "       [0.24378441, 0.75621559],\n",
       "       [0.52987304, 0.47012696],\n",
       "       [0.58269856, 0.41730144],\n",
       "       [0.57018386, 0.42981614],\n",
       "       [0.69883697, 0.30116303],\n",
       "       [0.43022535, 0.56977465],\n",
       "       [0.93493189, 0.06506811],\n",
       "       [0.81188595, 0.18811405],\n",
       "       [0.31192541, 0.68807459],\n",
       "       [0.23100808, 0.76899192],\n",
       "       [0.69905123, 0.30094877],\n",
       "       [0.78535592, 0.21464408],\n",
       "       [0.81013644, 0.18986356],\n",
       "       [0.59422655, 0.40577345],\n",
       "       [0.32087551, 0.67912449],\n",
       "       [0.65762925, 0.34237075],\n",
       "       [0.82453061, 0.17546939],\n",
       "       [0.50945167, 0.49054833],\n",
       "       [0.17566027, 0.82433973],\n",
       "       [0.83590435, 0.16409565],\n",
       "       [0.81875277, 0.18124723],\n",
       "       [0.58091829, 0.41908171],\n",
       "       [0.56049604, 0.43950396],\n",
       "       [0.60547532, 0.39452468],\n",
       "       [0.68171774, 0.31828226],\n",
       "       [0.37588506, 0.62411494],\n",
       "       [0.79225438, 0.20774562],\n",
       "       [0.77309816, 0.22690184],\n",
       "       [0.76383938, 0.23616062],\n",
       "       [0.43908244, 0.56091756],\n",
       "       [0.70549275, 0.29450725],\n",
       "       [0.47233049, 0.52766951],\n",
       "       [0.83398764, 0.16601236],\n",
       "       [0.79910634, 0.20089366],\n",
       "       [0.71592694, 0.28407306],\n",
       "       [0.7922604 , 0.2077396 ],\n",
       "       [0.5725272 , 0.4274728 ],\n",
       "       [0.62223369, 0.37776631],\n",
       "       [0.80554714, 0.19445286],\n",
       "       [0.23830813, 0.76169187],\n",
       "       [0.75622019, 0.24377981],\n",
       "       [0.45082662, 0.54917338],\n",
       "       [0.79911123, 0.20088877],\n",
       "       [0.72430382, 0.27569618],\n",
       "       [0.30467326, 0.69532674],\n",
       "       [0.87774294, 0.12225706],\n",
       "       [0.18439317, 0.81560683],\n",
       "       [0.53047026, 0.46952974],\n",
       "       [0.17055711, 0.82944289],\n",
       "       [0.7407102 , 0.2592898 ],\n",
       "       [0.47819512, 0.52180488],\n",
       "       [0.74048529, 0.25951471],\n",
       "       [0.76369416, 0.23630584],\n",
       "       [0.73730252, 0.26269748],\n",
       "       [0.42313527, 0.57686473],\n",
       "       [0.18561818, 0.81438182],\n",
       "       [0.96086264, 0.03913736],\n",
       "       [0.79223029, 0.20776971],\n",
       "       [0.81818455, 0.18181545],\n",
       "       [0.3140546 , 0.6859454 ],\n",
       "       [0.81539248, 0.18460752],\n",
       "       [0.23235692, 0.76764308],\n",
       "       [0.73194495, 0.26805505],\n",
       "       [0.55513058, 0.44486942],\n",
       "       [0.13784897, 0.86215103],\n",
       "       [0.2623466 , 0.7376534 ],\n",
       "       [0.31753637, 0.68246363],\n",
       "       [0.16122457, 0.83877543],\n",
       "       [0.1670973 , 0.8329027 ],\n",
       "       [0.7075132 , 0.2924868 ],\n",
       "       [0.62781655, 0.37218345],\n",
       "       [0.72374217, 0.27625783],\n",
       "       [0.71597283, 0.28402717],\n",
       "       [0.13310967, 0.86689033],\n",
       "       [0.54658126, 0.45341874],\n",
       "       [0.65839187, 0.34160813],\n",
       "       [0.56532557, 0.43467443],\n",
       "       [0.79857724, 0.20142276],\n",
       "       [0.43847244, 0.56152756],\n",
       "       [0.90089294, 0.09910706],\n",
       "       [0.53551938, 0.46448062],\n",
       "       [0.17711343, 0.82288657],\n",
       "       [0.73251043, 0.26748957],\n",
       "       [0.62064145, 0.37935855],\n",
       "       [0.19706498, 0.80293502],\n",
       "       [0.39859497, 0.60140503],\n",
       "       [0.61585791, 0.38414209],\n",
       "       [0.75169924, 0.24830076],\n",
       "       [0.69860978, 0.30139022],\n",
       "       [0.55033705, 0.44966295],\n",
       "       [0.9441889 , 0.0558111 ],\n",
       "       [0.72432451, 0.27567549],\n",
       "       [0.3497938 , 0.6502062 ],\n",
       "       [0.73252597, 0.26747403],\n",
       "       [0.58269856, 0.41730144],\n",
       "       [0.19439277, 0.80560723],\n",
       "       [0.26207144, 0.73792856],\n",
       "       [0.74846506, 0.25153494],\n",
       "       [0.78679179, 0.21320821],\n",
       "       [0.52028375, 0.47971625],\n",
       "       [0.16595419, 0.83404581],\n",
       "       [0.75585467, 0.24414533],\n",
       "       [0.58554249, 0.41445751],\n",
       "       [0.72384333, 0.27615667],\n",
       "       [0.71600877, 0.28399123],\n",
       "       [0.42035851, 0.57964149],\n",
       "       [0.78600503, 0.21399497],\n",
       "       [0.73245428, 0.26754572],\n",
       "       [0.72201376, 0.27798624],\n",
       "       [0.56777453, 0.43222547],\n",
       "       [0.17905862, 0.82094138],\n",
       "       [0.79242995, 0.20757005],\n",
       "       [0.53551938, 0.46448062],\n",
       "       [0.3969164 , 0.6030836 ],\n",
       "       [0.60547532, 0.39452468],\n",
       "       [0.47174648, 0.52825352],\n",
       "       [0.20703307, 0.79296693],\n",
       "       [0.80551276, 0.19448724],\n",
       "       [0.48084306, 0.51915694],\n",
       "       [0.19021133, 0.80978867],\n",
       "       [0.77033401, 0.22966599],\n",
       "       [0.87643306, 0.12356694],\n",
       "       [0.86537381, 0.13462619],\n",
       "       [0.72426729, 0.27573271],\n",
       "       [0.76574131, 0.23425869],\n",
       "       [0.85736715, 0.14263285],\n",
       "       [0.73013944, 0.26986056],\n",
       "       [0.80222174, 0.19777826],\n",
       "       [0.81192971, 0.18807029],\n",
       "       [0.56029089, 0.43970911],\n",
       "       [0.63471028, 0.36528972],\n",
       "       [0.2730717 , 0.7269283 ],\n",
       "       [0.5244278 , 0.4755722 ],\n",
       "       [0.7480341 , 0.2519659 ],\n",
       "       [0.61065944, 0.38934056],\n",
       "       [0.75611226, 0.24388774],\n",
       "       [0.15570659, 0.84429341],\n",
       "       [0.52411756, 0.47588244],\n",
       "       [0.92961522, 0.07038478],\n",
       "       [0.74048529, 0.25951471],\n",
       "       [0.74052865, 0.25947135],\n",
       "       [0.48294393, 0.51705607],\n",
       "       [0.90465269, 0.09534731],\n",
       "       [0.75613925, 0.24386075],\n",
       "       [0.36689582, 0.63310418],\n",
       "       [0.53061652, 0.46938348],\n",
       "       [0.3710347 , 0.6289653 ],\n",
       "       [0.77104931, 0.22895069],\n",
       "       [0.79222528, 0.20777472],\n",
       "       [0.86282749, 0.13717251],\n",
       "       [0.74056964, 0.25943036],\n",
       "       [0.26980027, 0.73019973],\n",
       "       [0.77100947, 0.22899053],\n",
       "       [0.51488396, 0.48511604],\n",
       "       [0.60551902, 0.39448098],\n",
       "       [0.7782725 , 0.2217275 ],\n",
       "       [0.91944176, 0.08055824],\n",
       "       [0.62245869, 0.37754131],\n",
       "       [0.7407102 , 0.2592898 ],\n",
       "       [0.41434144, 0.58565856],\n",
       "       [0.65271974, 0.34728026],\n",
       "       [0.28212664, 0.71787336],\n",
       "       [0.90452691, 0.09547309],\n",
       "       [0.47827415, 0.52172585],\n",
       "       [0.76383278, 0.23616722],\n",
       "       [0.19436622, 0.80563378],\n",
       "       [0.25823505, 0.74176495],\n",
       "       [0.47261925, 0.52738075],\n",
       "       [0.49026071, 0.50973929],\n",
       "       [0.81192041, 0.18807959],\n",
       "       [0.16746372, 0.83253628],\n",
       "       [0.73979101, 0.26020899],\n",
       "       [0.71597283, 0.28402717],\n",
       "       [0.75825288, 0.24174712],\n",
       "       [0.71604251, 0.28395749],\n",
       "       [0.72408825, 0.27591175],\n",
       "       [0.72544567, 0.27455433],\n",
       "       [0.75986639, 0.24013361],\n",
       "       [0.65939163, 0.34060837],\n",
       "       [0.63548285, 0.36451715],\n",
       "       [0.41081214, 0.58918786],\n",
       "       [0.67707529, 0.32292471],\n",
       "       [0.30918008, 0.69081992],\n",
       "       [0.76103641, 0.23896359],\n",
       "       [0.74832729, 0.25167271],\n",
       "       [0.59642922, 0.40357078],\n",
       "       [0.77711396, 0.22288604],\n",
       "       [0.23215006, 0.76784994],\n",
       "       [0.74839249, 0.25160751],\n",
       "       [0.08178322, 0.91821678],\n",
       "       [0.54488898, 0.45511102],\n",
       "       [0.31134292, 0.68865708],\n",
       "       [0.57032251, 0.42967749],\n",
       "       [0.58554249, 0.41445751],\n",
       "       [0.75567909, 0.24432091],\n",
       "       [0.76366226, 0.23633774],\n",
       "       [0.26939843, 0.73060157],\n",
       "       [0.54345737, 0.45654263],\n",
       "       [0.43164069, 0.56835931],\n",
       "       [0.34870316, 0.65129684],\n",
       "       [0.8567372 , 0.1432628 ],\n",
       "       [0.73254509, 0.26745491],\n",
       "       [0.51365633, 0.48634367],\n",
       "       [0.54488898, 0.45511102],\n",
       "       [0.42794219, 0.57205781],\n",
       "       [0.41181659, 0.58818341],\n",
       "       [0.29727761, 0.70272239],\n",
       "       [0.64425026, 0.35574974],\n",
       "       [0.87983878, 0.12016122],\n",
       "       [0.68689442, 0.31310558],\n",
       "       [0.86706276, 0.13293724],\n",
       "       [0.77104176, 0.22895824],\n",
       "       [0.74055677, 0.25944323],\n",
       "       [0.74849581, 0.25150419],\n",
       "       [0.51955321, 0.48044679],\n",
       "       [0.75245827, 0.24754173],\n",
       "       [0.78896133, 0.21103867],\n",
       "       [0.83011707, 0.16988293],\n",
       "       [0.45650301, 0.54349699],\n",
       "       [0.60030763, 0.39969237],\n",
       "       [0.50921667, 0.49078333],\n",
       "       [0.69001746, 0.30998254],\n",
       "       [0.7407102 , 0.2592898 ],\n",
       "       [0.65152053, 0.34847947],\n",
       "       [0.44829106, 0.55170894],\n",
       "       [0.28536676, 0.71463324],\n",
       "       [0.47316641, 0.52683359],\n",
       "       [0.40235851, 0.59764149],\n",
       "       [0.27762062, 0.72237938],\n",
       "       [0.69860978, 0.30139022],\n",
       "       [0.7407102 , 0.2592898 ],\n",
       "       [0.24605174, 0.75394826],\n",
       "       [0.58554249, 0.41445751],\n",
       "       [0.76027401, 0.23972599],\n",
       "       [0.41893411, 0.58106589],\n",
       "       [0.56622437, 0.43377563],\n",
       "       [0.73256898, 0.26743102],\n",
       "       [0.84694372, 0.15305628],\n",
       "       [0.90456482, 0.09543518],\n",
       "       [0.76345994, 0.23654006],\n",
       "       [0.28689286, 0.71310714],\n",
       "       [0.61809711, 0.38190289],\n",
       "       [0.49887224, 0.50112776],\n",
       "       [0.69011135, 0.30988865],\n",
       "       [0.88935905, 0.11064095],\n",
       "       [0.59284481, 0.40715519],\n",
       "       [0.53810713, 0.46189287],\n",
       "       [0.77807882, 0.22192118],\n",
       "       [0.77829775, 0.22170225],\n",
       "       [0.39007699, 0.60992301],\n",
       "       [0.67905822, 0.32094178],\n",
       "       [0.79160633, 0.20839367],\n",
       "       [0.85374968, 0.14625032],\n",
       "       [0.3606113 , 0.6393887 ],\n",
       "       [0.81195299, 0.18804701],\n",
       "       [0.70760404, 0.29239596],\n",
       "       [0.42151867, 0.57848133],\n",
       "       [0.78534151, 0.21465849],\n",
       "       [0.32359036, 0.67640964],\n",
       "       [0.69001746, 0.30998254],\n",
       "       [0.4708459 , 0.5291541 ],\n",
       "       [0.81191388, 0.18808612],\n",
       "       [0.42697976, 0.57302024],\n",
       "       [0.84921074, 0.15078926],\n",
       "       [0.4718731 , 0.5281269 ],\n",
       "       [0.83436213, 0.16563787],\n",
       "       [0.52430006, 0.47569994],\n",
       "       [0.19834163, 0.80165837],\n",
       "       [0.7399823 , 0.2600177 ],\n",
       "       [0.44531372, 0.55468628],\n",
       "       [0.32413707, 0.67586293],\n",
       "       [0.85748715, 0.14251285],\n",
       "       [0.45032549, 0.54967451],\n",
       "       [0.45295507, 0.54704493],\n",
       "       [0.80081823, 0.19918177],\n",
       "       [0.7245071 , 0.2754929 ],\n",
       "       [0.81191388, 0.18808612],\n",
       "       [0.71631368, 0.28368632],\n",
       "       [0.76935063, 0.23064937],\n",
       "       [0.6362915 , 0.3637085 ],\n",
       "       [0.86248707, 0.13751293],\n",
       "       [0.84787072, 0.15212928],\n",
       "       [0.84787072, 0.15212928],\n",
       "       [0.48239582, 0.51760418],\n",
       "       [0.29597814, 0.70402186],\n",
       "       [0.74074533, 0.25925467],\n",
       "       [0.68110389, 0.31889611],\n",
       "       [0.83598463, 0.16401537],\n",
       "       [0.78903277, 0.21096723],\n",
       "       [0.26194462, 0.73805538],\n",
       "       [0.29650535, 0.70349465],\n",
       "       [0.59272528, 0.40727472],\n",
       "       [0.35907543, 0.64092457],\n",
       "       [0.79954446, 0.20045554],\n",
       "       [0.80229139, 0.19770861],\n",
       "       [0.52924569, 0.47075431],\n",
       "       [0.52430006, 0.47569994],\n",
       "       [0.58643006, 0.41356994],\n",
       "       [0.8891068 , 0.1108932 ],\n",
       "       [0.36042432, 0.63957568],\n",
       "       [0.83030788, 0.16969212],\n",
       "       [0.76107324, 0.23892676],\n",
       "       [0.43253844, 0.56746156],\n",
       "       [0.40873241, 0.59126759],\n",
       "       [0.67453227, 0.32546773],\n",
       "       [0.72392377, 0.27607623],\n",
       "       [0.4095557 , 0.5904443 ],\n",
       "       [0.26939843, 0.73060157],\n",
       "       [0.79044924, 0.20955076],\n",
       "       [0.88099111, 0.11900889],\n",
       "       [0.1275055 , 0.8724945 ],\n",
       "       [0.13812918, 0.86187082],\n",
       "       [0.5139701 , 0.4860299 ],\n",
       "       [0.83014889, 0.16985111],\n",
       "       [0.8471041 , 0.1528959 ],\n",
       "       [0.68597731, 0.31402269],\n",
       "       [0.32246765, 0.67753235],\n",
       "       [0.52987304, 0.47012696],\n",
       "       [0.53169535, 0.46830465],\n",
       "       [0.41645659, 0.58354341],\n",
       "       [0.10075   , 0.89925   ],\n",
       "       [0.40287852, 0.59712148],\n",
       "       [0.48777181, 0.51222819],\n",
       "       [0.85990446, 0.14009554],\n",
       "       [0.5330413 , 0.4669587 ],\n",
       "       [0.81799127, 0.18200873],\n",
       "       [0.47782998, 0.52217002],\n",
       "       [0.16380259, 0.83619741],\n",
       "       [0.6629847 , 0.3370153 ],\n",
       "       [0.70752707, 0.29247293],\n",
       "       [0.72432451, 0.27567549],\n",
       "       [0.6629847 , 0.3370153 ],\n",
       "       [0.75303294, 0.24696706],\n",
       "       [0.76369416, 0.23630584],\n",
       "       [0.31766932, 0.68233068],\n",
       "       [0.77661189, 0.22338811],\n",
       "       [0.71597777, 0.28402223],\n",
       "       [0.7322786 , 0.2677214 ],\n",
       "       [0.27953712, 0.72046288],\n",
       "       [0.70689325, 0.29310675],\n",
       "       [0.86710632, 0.13289368],\n",
       "       [0.83261551, 0.16738449],\n",
       "       [0.77106005, 0.22893995],\n",
       "       [0.85222601, 0.14777399],\n",
       "       [0.80319257, 0.19680743],\n",
       "       [0.57081137, 0.42918863],\n",
       "       [0.7325403 , 0.2674597 ],\n",
       "       [0.31513822, 0.68486178],\n",
       "       [0.47261925, 0.52738075],\n",
       "       [0.77085118, 0.22914882],\n",
       "       [0.74072801, 0.25927199],\n",
       "       [0.49917896, 0.50082104],\n",
       "       [0.70790672, 0.29209328],\n",
       "       [0.67707529, 0.32292471],\n",
       "       [0.88310567, 0.11689433],\n",
       "       [0.73245428, 0.26754572],\n",
       "       [0.56422349, 0.43577651],\n",
       "       [0.26879241, 0.73120759],\n",
       "       [0.70704231, 0.29295769],\n",
       "       [0.86723345, 0.13276655],\n",
       "       [0.26990558, 0.73009442],\n",
       "       [0.37880429, 0.62119571],\n",
       "       [0.321478  , 0.678522  ],\n",
       "       [0.69908331, 0.30091669],\n",
       "       [0.72861168, 0.27138832],\n",
       "       [0.35120776, 0.64879224],\n",
       "       [0.53810713, 0.46189287],\n",
       "       [0.37784668, 0.62215332],\n",
       "       [0.26142725, 0.73857275],\n",
       "       [0.70736049, 0.29263951]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = logit.predict_proba(X_train[['age','fare','pclass']])\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit.score(X_train[['age','fare','pclass']], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[194  43]\n",
      " [ 77  85]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.82      0.76       237\n",
      "           1       0.66      0.52      0.59       162\n",
      "\n",
      "    accuracy                           0.70       399\n",
      "   macro avg       0.69      0.67      0.67       399\n",
      "weighted avg       0.69      0.70      0.69       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 2 \n",
    "logit_2 = LogisticRegression(C=1, class_weight=None, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_2.fit(X_train[['age','fare','pclass','sex_male']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-2.89750071e-02 -2.73597169e-05 -1.14185800e+00 -2.22510766e+00]]\n",
      "Intercept: \n",
      " [4.33626934]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_2.coef_)\n",
    "print('Intercept: \\n', logit_2.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = logit_2.predict(X_train[['age','fare','pclass','sex_male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_2 = logit_2.predict_proba(X_train[['age','fare','pclass','sex_male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 2 Logistic Regression classifier on training set: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 2 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_2.score(X_train[['age','fare','pclass','sex_male']], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200  37]\n",
      " [ 48 114]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       237\n",
      "           1       0.75      0.70      0.73       162\n",
      "\n",
      "    accuracy                           0.79       399\n",
      "   macro avg       0.78      0.77      0.78       399\n",
      "weighted avg       0.79      0.79      0.79       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 3 \n",
    "logit_3 = LogisticRegression(C=1, class_weight=None, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_3.fit(X_train[['pclass','sex_male']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.9235693  -2.34900994]]\n",
      "Intercept: \n",
      " [3.06098849]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_3.coef_)\n",
    "print('Intercept: \\n', logit_3.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3 = logit_3.predict(X_train[['pclass','sex_male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_3 = logit_3.predict_proba(X_train[['pclass','sex_male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 3 Logistic Regression classifier on training set: 0.78\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 3 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_3.score(X_train[['pclass','sex_male']], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[202  35]\n",
      " [ 52 110]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.82       237\n",
      "           1       0.76      0.68      0.72       162\n",
      "\n",
      "    accuracy                           0.78       399\n",
      "   macro avg       0.78      0.77      0.77       399\n",
      "weighted avg       0.78      0.78      0.78       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 4\n",
    "logit_4 = LogisticRegression(C=1, class_weight=None, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_4.fit(X_train[['pclass','age']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-1.24286685 -0.04194852]]\n",
      "Intercept: \n",
      " [3.60268583]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_4.coef_)\n",
    "print('Intercept: \\n', logit_4.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_4 = logit_4.predict(X_train[['pclass','age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_4 = logit_4.predict_proba(X_train[['pclass','age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 4 Logistic Regression classifier on training set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 4 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_4.score(X_train[['pclass','age']], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193  44]\n",
      " [ 77  85]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76       237\n",
      "           1       0.66      0.52      0.58       162\n",
      "\n",
      "    accuracy                           0.70       399\n",
      "   macro avg       0.69      0.67      0.67       399\n",
      "weighted avg       0.69      0.70      0.69       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 5 - Class weight is balanced\n",
    "logit_5 = LogisticRegression(C=1, class_weight='balanced', random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', random_state=123)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.31234071 -0.03225086 -0.68823339  0.00230223 -0.54008143 -0.51085153\n",
      "  -1.31057493 -2.18738722]]\n",
      "Intercept: \n",
      " [4.26879098]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_5.coef_)\n",
    "print('Intercept: \\n', logit_5.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_5 = logit_5.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_5 = logit_5.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 5 Logistic Regression classifier on training set: 0.81\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 5 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_5.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[197  40]\n",
      " [ 36 126]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84       237\n",
      "           1       0.76      0.78      0.77       162\n",
      "\n",
      "    accuracy                           0.81       399\n",
      "   macro avg       0.80      0.80      0.80       399\n",
      "weighted avg       0.81      0.81      0.81       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight='balanced', random_state=123)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the object for Model 6 - Class weight is balanced, C is decreased\n",
    "logit_6 = LogisticRegression(C=.3, class_weight='balanced', random_state=123, intercept_scaling=1, solver='lbfgs')\n",
    "#Fit the train data set to the model\n",
    "logit_6.fit(X_train[['pclass','sex_male']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.8280761  -2.01129476]]\n",
      "Intercept: \n",
      " [3.0142318]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_6.coef_)\n",
    "print('Intercept: \\n', logit_6.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_6 = logit_6.predict(X_train[['pclass','sex_male']])\n",
    "\n",
    "y_pred_proba_6 = logit_6.predict_proba(X_train[['pclass','sex_male']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 6 Logistic Regression classifier on training set: 0.75\n",
      "[[167  70]\n",
      " [ 31 131]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.70      0.77       237\n",
      "           1       0.65      0.81      0.72       162\n",
      "\n",
      "    accuracy                           0.75       399\n",
      "   macro avg       0.75      0.76      0.74       399\n",
      "weighted avg       0.77      0.75      0.75       399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 6 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_6.score(X_train[['pclass','sex_male']], y_train)))\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred_6))\n",
    "\n",
    "print(classification_report(y_train, y_pred_6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use you best 3 models to predict and evaluate on your validate sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Models 2, 3, and 5 performed the best on the in sample data set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2: solver = lbfgs, c = 1\n",
      "Accuracy: 0.7674\n",
      "[[86 16]\n",
      " [24 46]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       102\n",
      "           1       0.74      0.66      0.70        70\n",
      "\n",
      "    accuracy                           0.77       172\n",
      "   macro avg       0.76      0.75      0.75       172\n",
      "weighted avg       0.77      0.77      0.76       172\n",
      "\n",
      "Model 3: solver = lbfgs, c = 1\n",
      "Accuracy: 0.7500\n",
      "[[86 16]\n",
      " [27 43]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80       102\n",
      "           1       0.73      0.61      0.67        70\n",
      "\n",
      "    accuracy                           0.75       172\n",
      "   macro avg       0.74      0.73      0.73       172\n",
      "weighted avg       0.75      0.75      0.75       172\n",
      "\n",
      "Model 5: solver = lbfgs, c = 1\n",
      "Accuracy: 0.7733\n",
      "[[81 21]\n",
      " [18 52]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.81       102\n",
      "           1       0.71      0.74      0.73        70\n",
      "\n",
      "    accuracy                           0.77       172\n",
      "   macro avg       0.77      0.77      0.77       172\n",
      "weighted avg       0.78      0.77      0.77       172\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "\n",
    "y_pred_2 = logit_2.predict(X_validate[['age','fare','pclass','sex_male']])\n",
    "y_pred_3 = logit_3.predict(X_validate[['pclass','sex_male']])\n",
    "y_pred_5 = logit_5.predict(X_validate)\n",
    "\n",
    "print(\"Model 2: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 2\n",
    "print('Accuracy: {:.4f}'.format(logit_2.score(X_validate[['age','fare','pclass','sex_male']], y_validate)))\n",
    "\n",
    "# confusion matrix of model 2\n",
    "print(confusion_matrix(y_validate, y_pred_2))\n",
    "\n",
    "# classification report of model 2\n",
    "print(classification_report(y_validate, y_pred_2))\n",
    "\n",
    "print(\"Model 3: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 3\n",
    "print('Accuracy: {:.4f}'.format(logit_3.score(X_validate[['pclass','sex_male']], y_validate)))\n",
    "\n",
    "# confusion matrix of model 3\n",
    "print(confusion_matrix(y_validate, y_pred_3))\n",
    "\n",
    "# classification report of model 3\n",
    "print(classification_report(y_validate, y_pred_3))\n",
    "\n",
    "print(\"Model 5: solver = lbfgs, c = 1\")\n",
    "\n",
    "# accuracy of model 5\n",
    "print('Accuracy: {:.4f}'.format(logit_5.score(X_validate, y_validate)))\n",
    "\n",
    "# confusion matrix of model 5\n",
    "print(confusion_matrix(y_validate, y_pred_5))\n",
    "\n",
    "# classification report of model 5\n",
    "print(classification_report(y_validate, y_pred_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model 5 performed the best on my validate data set***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 5: solver = lbfgs, c = 1\n",
      "Accuracy: 0.82\n",
      "[[68 17]\n",
      " [ 9 49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.80      0.84        85\n",
      "           1       0.74      0.84      0.79        58\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.81      0.82      0.81       143\n",
      "weighted avg       0.83      0.82      0.82       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logit_5.predict(X_test)\n",
    "y_pred_proba = logit_5.predict_proba(X_test)\n",
    "\n",
    "print(\"Model 5: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit_5.score(X_test, y_test)))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Model 5 performed marginally better on the test data set compared to both validate and train data sets.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus1: How do different strategies for handling the missing values in the age column affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = get_titanic_data()\n",
    "\n",
    "#Preapare the data: Drop columns \n",
    "columns_to_drop = ['Unnamed: 0', 'embark_town', 'embarked', 'deck',  'parch', 'passenger_id', 'class']\n",
    "titanic.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "#encode the feature \"sex\"\n",
    "df = pd.get_dummies(titanic[['sex']], drop_first=[True])\n",
    "\n",
    "#Concat dummies df with Titanic and drop the original coloumn sex\n",
    "titanic = pd.concat([titanic, dummies], axis=1).drop(columns='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(titanic, test_size=.2, random_state=123, stratify=titanic.survived)\n",
    "train, validate = train_test_split(train, test_size=.3, random_state=123, stratify=train.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy = 'most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = imputer.fit(train[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['age']] = imputer.transform(train[['age']])\n",
    "\n",
    "validate[['age']] = imputer.transform(validate[['age']])\n",
    "\n",
    "test[['age']] = imputer.transform(test[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 498 entries, 583 to 744\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   survived      498 non-null    int64  \n",
      " 1   pclass        498 non-null    int64  \n",
      " 2   age           498 non-null    float64\n",
      " 3   sibsp         498 non-null    int64  \n",
      " 4   fare          498 non-null    float64\n",
      " 5   alone         498 non-null    int64  \n",
      " 6   class_Second  498 non-null    uint8  \n",
      " 7   class_Third   498 non-null    uint8  \n",
      " 8   sex_male      498 non-null    uint8  \n",
      "dtypes: float64(2), int64(4), uint8(3)\n",
      "memory usage: 28.7 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', random_state=123)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create the object for Model 1A - Class weight is balanced, C is decreased\n",
    "logit_1a = LogisticRegression(C=1, class_weight='balanced', random_state=123, intercept_scaling=1, solver='lbfgs')\n",
    "#Fit the train data set to the model\n",
    "logit_1a.fit(X_train[['pclass','fare','age']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.95476003  0.00155782 -0.03010003]]\n",
      "Intercept: \n",
      " [2.98405054]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_1a.coef_)\n",
    "print('Intercept: \\n', logit_1a.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1a = logit_1a.predict(X_train[['pclass','fare', 'age']])\n",
    "\n",
    "y_pred_proba_1a = logit_1a.predict_proba(X_train[['pclass','fare', 'age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 1a Logistic Regression classifier on training set: 0.66\n",
      "[[211  96]\n",
      " [ 71 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.69      0.72       307\n",
      "           1       0.56      0.63      0.59       191\n",
      "\n",
      "    accuracy                           0.66       498\n",
      "   macro avg       0.65      0.66      0.65       498\n",
      "weighted avg       0.67      0.66      0.67       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 1a Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_1a.score(X_train[['pclass','fare', 'age']], y_train)))\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred_1a))\n",
    "\n",
    "print(classification_report(y_train, y_pred_1a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare how Model 5 does with training data where nulls in age were imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 5a - Class weight is balanced\n",
    "logit_5a = LogisticRegression(C=1, class_weight='balanced', random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', random_state=123)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_5a.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-3.47323045e-01 -2.96905285e-02 -5.75862975e-01 -4.32887575e-05\n",
      "  -6.29213931e-01 -3.94482230e-01 -1.28197292e+00 -2.61991658e+00]]\n",
      "Intercept: \n",
      " [4.6116662]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_5a.coef_)\n",
    "print('Intercept: \\n', logit_5a.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_5a = logit_5a.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_5a = logit_5a.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 5 Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 5 Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_5a.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[250  57]\n",
      " [ 41 150]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_5a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.81      0.84       307\n",
      "           1       0.72      0.79      0.75       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.80      0.79       498\n",
      "weighted avg       0.81      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_5a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways: ***Model 5 does slightly worse on in-sample data where nulls in age were imputed***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does Model 5a perfom on out-of-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_5a = logit_5a.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_5a = logit_5a.predict_proba(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7617\n",
      "[[106  26]\n",
      " [ 25  57]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81       132\n",
      "           1       0.69      0.70      0.69        82\n",
      "\n",
      "    accuracy                           0.76       214\n",
      "   macro avg       0.75      0.75      0.75       214\n",
      "weighted avg       0.76      0.76      0.76       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accuracy of model 5a\n",
    "print('Accuracy: {:.4f}'.format(logit_5a.score(X_validate, y_validate)))\n",
    "\n",
    "# confusion matrix of model 5a\n",
    "print(confusion_matrix(y_validate, y_pred_5a))\n",
    "\n",
    "# classification report of model 5\n",
    "print(classification_report(y_validate, y_pred_5a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Takeaways: ***Model 5 does slightly worse on out-of-sample data where nulls in age were imputed***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus2: How do different strategies for encoding sex affect model performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = get_titanic_data()\n",
    "\n",
    "#Preapare the data: Drop columns \n",
    "columns_to_drop = ['Unnamed: 0', 'embark_town', 'embarked', 'deck',  'parch', 'passenger_id', 'class']\n",
    "titanic.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "##encode the feature \"sex\"\n",
    "#df = pd.get_dummies(titanic[['sex']], drop_first=[False,False])\n",
    "#\n",
    "##Concat dummies df with Titanic and drop the original coloumn sex\n",
    "#titanic = pd.concat([titanic, dummies], axis=1).drop(columns='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp     fare  alone\n",
       "0         0       3    male  22.0      1   7.2500      0\n",
       "1         1       1  female  38.0      1  71.2833      0\n",
       "2         1       3  female  26.0      0   7.9250      1\n",
       "3         1       1  female  35.0      1  53.1000      0\n",
       "4         0       3    male  35.0      0   8.0500      1"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['sex'] = titanic.sex.apply(lambda n: 0 if n == \"male\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass  sex   age  sibsp     fare  alone\n",
       "0         0       3    0  22.0      1   7.2500      0\n",
       "1         1       1    1  38.0      1  71.2833      0\n",
       "2         1       3    1  26.0      0   7.9250      1\n",
       "3         1       1    1  35.0      1  53.1000      0\n",
       "4         0       3    0  35.0      0   8.0500      1"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into train, validate, and test\n",
    "#stratidfy by survived \n",
    "train, validate, test = train_validate_test_split(titanic, target='survived', seed=123)\n",
    "\n",
    "X_train = train.drop(columns=['survived'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the object for Model 3 \n",
    "logit_3a = LogisticRegression(C=1, class_weight=None, random_state=123, intercept_scaling=1, solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the train data set to the model\n",
    "logit_3a.fit(X_train[['pclass','sex']], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [[-0.97338731  2.71283588]]\n",
      "Intercept: \n",
      " [0.64934851]\n"
     ]
    }
   ],
   "source": [
    "print('Coefficient: \\n', logit_3a.coef_)\n",
    "print('Intercept: \\n', logit_3a.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_3a = logit_3a.predict(X_train[['pclass','sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_3a = logit_3a.predict_proba(X_train[['pclass','sex']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Model 3a Logistic Regression classifier on training set: 0.80\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of Model 3a Logistic Regression classifier on training set: {:.2f}'\n",
    "     .format(logit_3a.score(X_train[['pclass','sex']], y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[265  42]\n",
      " [ 58 133]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_3a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84       307\n",
      "           1       0.76      0.70      0.73       191\n",
      "\n",
      "    accuracy                           0.80       498\n",
      "   macro avg       0.79      0.78      0.78       498\n",
      "weighted avg       0.80      0.80      0.80       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_3a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3a does better on in-sample data with sex encoded with 0s and 1s in column as opposed to getting dummies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
